,Title,URL,Date,Abstruct,Category
0,"Efficient Fine-Tuning with Domain Adaptation for Privacy-Preserving
  Vision Transformer",http://arxiv.org/abs/2401.05126v2,2024-01-10T12:46:31Z,"We propose a novel method for privacy-preserving deep neural networks (DNNs)
with the Vision Transformer (ViT). The method allows us not only to train
models and test with visually protected images but to also avoid the
performance degradation caused from the use of encrypted images, whereas
conventional methods cannot avoid the influence of image encryption. A domain
adaptation method is used to efficiently fine-tune ViT with encrypted images.
In experiments, the method is demonstrated to outperform conventional methods
in an image classification task on the CIFAR-10 and ImageNet datasets in terms
of classification accuracy.",cs.CV
1,Masked LoGoNet: Fast and Accurate 3D Image Analysis for Medical Domain,http://arxiv.org/abs/2402.06190v1,2024-02-09T05:06:58Z,"Standard modern machine-learning-based imaging methods have faced challenges
in medical applications due to the high cost of dataset construction and,
thereby, the limited labeled training data available. Additionally, upon
deployment, these methods are usually used to process a large volume of data on
a daily basis, imposing a high maintenance cost on medical facilities. In this
paper, we introduce a new neural network architecture, termed LoGoNet, with a
tailored self-supervised learning (SSL) method to mitigate such challenges.
LoGoNet integrates a novel feature extractor within a U-shaped architecture,
leveraging Large Kernel Attention (LKA) and a dual encoding strategy to capture
both long-range and short-range feature dependencies adeptly. This is in
contrast to existing methods that rely on increasing network capacity to
enhance feature extraction. This combination of novel techniques in our model
is especially beneficial in medical image segmentation, given the difficulty of
learning intricate and often irregular body organ shapes, such as the spleen.
Complementary, we propose a novel SSL method tailored for 3D images to
compensate for the lack of large labeled datasets. The method combines masking
and contrastive learning techniques within a multi-task learning framework and
is compatible with both Vision Transformer (ViT) and CNN-based models. We
demonstrate the efficacy of our methods in numerous tasks across two standard
datasets (i.e., BTCV and MSD). Benchmark comparisons with eight
state-of-the-art models highlight LoGoNet's superior performance in both
inference time and accuracy.",cs.CV
2,"NeRCC: Nested-Regression Coded Computing for Resilient Distributed
  Prediction Serving Systems",http://arxiv.org/abs/2402.04377v2,2024-02-06T20:31:15Z,"Resilience against stragglers is a critical element of prediction serving
systems, tasked with executing inferences on input data for a pre-trained
machine-learning model. In this paper, we propose NeRCC, as a general
straggler-resistant framework for approximate coded computing. NeRCC includes
three layers: (1) encoding regression and sampling, which generates coded data
points, as a combination of original data points, (2) computing, in which a
cluster of workers run inference on the coded data points, (3) decoding
regression and sampling, which approximately recovers the predictions of the
original data points from the available predictions on the coded data points.
We argue that the overall objective of the framework reveals an underlying
interconnection between two regression models in the encoding and decoding
layers. We propose a solution to the nested regressions problem by summarizing
their dependence on two regularization terms that are jointly optimized. Our
extensive experiments on different datasets and various machine learning
models, including LeNet5, RepVGG, and Vision Transformer (ViT), demonstrate
that NeRCC accurately approximates the original predictions in a wide range of
stragglers, outperforming the state-of-the-art by up to 23%.",cs.LG
